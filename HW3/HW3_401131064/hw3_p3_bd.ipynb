{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4DYKCyDYFExf"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rt0-R_L5A_KB"
      },
      "outputs": [],
      "source": [
        "class MatrixFactorization:\n",
        "    def __init__(self, num_items, num_users, num_factors, learning_rate, regularization_rate, num_iterations):\n",
        "        \"\"\"\n",
        "        Initialize the Matrix Factorization model.\n",
        "\n",
        "        Args:\n",
        "            num_items (int): Number of items.\n",
        "            num_users (int): Number of users.\n",
        "            num_factors (int): Number of latent factors.\n",
        "            learning_rate (float): Learning rate for gradient descent.\n",
        "            regularization_rate (float): Regularization rate for L2 regularization.\n",
        "            num_iterations (int): Number of iterations for training.\n",
        "        \"\"\"\n",
        "        self.num_items = num_items\n",
        "        self.num_users = num_users\n",
        "        self.num_factors = num_factors\n",
        "        self.learning_rate = learning_rate\n",
        "        self.regularization_rate = regularization_rate\n",
        "        self.num_iterations = num_iterations\n",
        "\n",
        "\n",
        "        # Initialize Q and P matrices with random values\n",
        "        # Start your code\n",
        "        #self.P = np.random.normal(\n",
        "          #  scale=1./self.num_factors, size=(self.num_users, self.num_factors))\n",
        "        #self.Q = np.random.normal(\n",
        "         #   scale=1./self.num_factors, size=(self.num_items, self.num_factors))\n",
        "        self.P = np.random.rand(self.num_users, self.num_factors)\n",
        "        self.Q = np.random.rand(self.num_items, self.num_factors)\n",
        "        # End your code\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        \"\"\"\n",
        "        Compute the sigmoid function.\n",
        "\n",
        "        Args:\n",
        "            x (float): Input value.\n",
        "\n",
        "        Returns:\n",
        "            float: Sigmoid value.\n",
        "        \"\"\"\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def update_parameters(self, R):\n",
        "        \"\"\"\n",
        "        Update the parameters Q and P using Stochastic Gradient Descent.\n",
        "\n",
        "        Args:\n",
        "            R (ndarray): Rating matrix.\n",
        "        \"\"\"\n",
        "        # Start your code\n",
        "\n",
        "        self.R = R\n",
        "        self.samples = [\n",
        "            (i, j, self.R[i, j])\n",
        "            for i in range(self.num_users)\n",
        "            for j in range(self.num_items)\n",
        "            if self.R[i, j] > 0\n",
        "        ]\n",
        "        for n in range(self.num_iterations):\n",
        "            np.random.shuffle(self.samples)\n",
        "            for u, i, r in self.samples:\n",
        "              # Computer prediction and error\n",
        "              prediction = self.predict_rating(i, u)\n",
        "              sigmoid_grad = 1 - self.sigmoid(r - prediction)\n",
        "              # Update user and item latent feature matrices\n",
        "              self.Q[i, :] -= self.learning_rate * (((-1) * sigmoid_grad * self.P[u, :]) + 2 * self.regularization_rate * self.Q[i, :])\n",
        "              self.P[u, :] -= self.learning_rate * (((-1) * sigmoid_grad * self.Q[i, :]) + 2 * self.regularization_rate * self.P[u, :])\n",
        "        # End your code\n",
        "\n",
        "    def train(self, R):\n",
        "        \"\"\"\n",
        "        Train the Matrix Factorization model.\n",
        "\n",
        "        Args:\n",
        "            R (ndarray): Rating matrix.\n",
        "        \"\"\"\n",
        "        self.update_parameters(R)\n",
        "\n",
        "    def predict_rating(self, i, u):\n",
        "        \"\"\"\n",
        "        Predict the rating for item i and user u.\n",
        "\n",
        "        Args:\n",
        "            i (int): Item index.\n",
        "            u (int): User index.\n",
        "\n",
        "        Returns:\n",
        "            float: Predicted rating.\n",
        "        \"\"\"\n",
        "        # Start your code\n",
        "        return self.Q[i, :].dot(self.P[u, :].T)\n",
        "        # End your code\n",
        "\n",
        "    def evaluate(self, users_list, groundTruth_list, topk=10):\n",
        "        \"\"\"\n",
        "        Evaluate trained model for item i and user u\n",
        "\n",
        "        Args:\n",
        "            users_list (list): Users indexes list.\n",
        "            groundTruth_list (list) : list of items in users test set\n",
        "            topk (int): threshold for top item selection\n",
        "\n",
        "        Returns:\n",
        "            float: sum(Intersection between topk predicted items and user profile in test set / user profile size in test set) / len(users_list)\n",
        "        \"\"\"\n",
        "        # Start your code\n",
        "\n",
        "        num_users = len(users_list)\n",
        "        total_precision = 0\n",
        "\n",
        "        for u in users_list:\n",
        "\n",
        "           ground_truth = groundTruth_list[u]\n",
        "           predicted_ratings = np.dot(self.Q , self.P[u, :].T)\n",
        "           sorted_indices = np.argsort(predicted_ratings)[::-1]\n",
        "           top_items = sorted_indices[:topk]\n",
        "           intersection = set(top_items).intersection(ground_truth)\n",
        "           precision = len(intersection) / len(ground_truth)\n",
        "           total_precision += precision\n",
        "\n",
        "        average_precision = total_precision / num_users\n",
        "\n",
        "        return average_precision\n",
        "\n",
        "        # End your code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nL-zogsUmejR"
      },
      "outputs": [],
      "source": [
        "def read_data(filename):\n",
        "    data = []\n",
        "\n",
        "    with open(filename, 'r') as file:\n",
        "        for line in file:\n",
        "            items = line.strip().split(' ')\n",
        "            user_id = int(items[0])\n",
        "            item_ids = [int(item) for item in items[1:]]\n",
        "            data.append((user_id, item_ids))\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sv2Gwvx6knwC",
        "outputId": "c664d77c-2bff-4f7b-a7ad-dd8c1f1a82fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/My Drive/data-bd.txt\"\n",
        "data = read_data(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RZBus8C242Ye"
      },
      "outputs": [],
      "source": [
        "num_items = None\n",
        "num_users = len(data)\n",
        "num_factors = 200\n",
        "regularization_rate = 0.1\n",
        "num_iterations = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6rxjPJT54Y3g"
      },
      "outputs": [],
      "source": [
        "item_set = set()\n",
        "\n",
        "for user_id, item_ids in data:\n",
        "  item_set.update(item_ids)\n",
        "\n",
        "num_items = len(item_set)\n",
        "\n",
        "R = np.zeros((num_users, num_items))\n",
        "for i, (user_id, item_ids) in enumerate(data):\n",
        "        for item_id in item_ids:\n",
        "            R[i, item_id] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pSRtC-AQhlA5"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "R_train = R\n",
        "user_test_list = random.sample(range(0, num_users), int(num_users*0.4))\n",
        "for i in user_test_list:\n",
        "   (user_id, item_ids) = data[i]\n",
        "   item_test_list = random.sample(item_ids, int(len(item_ids)*0.2))\n",
        "   for item_id in item_test_list:\n",
        "            R_train[i, item_id] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUJ2p_t0hhln",
        "outputId": "d7237b9e-8c00-42e1-c009-3fd37f76c764"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29858, 40981)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "R_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqGhFUm_mZBx",
        "outputId": "a94671c4-7bca-4086-c890-e78d3085557e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning_rate = 0.0001\n",
            "Predicted rating for item 0 and user 0: 75.71717332965171\n",
            "Accuracy for model: 0.016721959788646965\n",
            "********************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-afb18204880e>:42: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning_rate = 0.001\n",
            "Predicted rating for item 0 and user 0: 1296.0185373579154\n",
            "Accuracy for model: 0.006240015502583984\n",
            "********************************************\n",
            "Learning_rate = 0.015\n",
            "Predicted rating for item 0 and user 0: 1.1173554975690635e+32\n",
            "Accuracy for model: 0.0064323211414480455\n",
            "********************************************\n",
            "Learning_rate = 0.1\n",
            "Predicted rating for item 0 and user 0: 3.5574048719900194e+235\n",
            "Accuracy for model: 0.004659644174148825\n",
            "********************************************\n"
          ]
        }
      ],
      "source": [
        "learning_rate_list = [0.0001,0.001,0.015,0.1]\n",
        "\n",
        "for learning_rate in learning_rate_list:\n",
        "\n",
        "    model = MatrixFactorization(num_items, num_users, num_factors, learning_rate, regularization_rate,\n",
        "                            num_iterations)\n",
        "    model.train(R_train)\n",
        "\n",
        "    print(f\"Learning_rate = {learning_rate}\")\n",
        "    # Test prediction for item 0 and user 0\n",
        "    item_index = 0\n",
        "    user_index = 0\n",
        "    prediction = model.predict_rating(item_index, user_index)\n",
        "    print(f\"Predicted rating for item {item_index} and user {user_index}: {prediction}\")\n",
        "\n",
        "    # Evaluate model for users in test set\n",
        "\n",
        "\n",
        "    user_indexes = user_test_list\n",
        "    groudTruths = {}\n",
        "\n",
        "    for i in user_test_list :\n",
        "        (user_id, item_ids) = data[i]\n",
        "        groudTruths[user_id]=item_ids\n",
        "\n",
        "    result = model.evaluate(user_indexes, groudTruths)\n",
        "    print(f\"Accuracy for model: {result}\")\n",
        "    print(\"********************************************\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "phH0DU5pDbA1"
      },
      "execution_count": 9,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}